{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReadingFilefromClonedRepo_ReadingCheckpoints.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MYDoveLsOsG",
        "outputId": "4301cb02-ab01-49c9-ed0b-e328ac74c07c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TswpkVVIsQSK",
        "outputId": "61b4e809-1ca6-4808-ac9d-82d844bc9329"
      },
      "source": [
        "#  !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "# !pip3 install torchvision\n",
        "!pip install easydict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36YuN9i3sVQz"
      },
      "source": [
        "#  Created by Soniya  on 31/10/18.\n",
        "#\n",
        "import torch\n",
        "import numpy\n",
        "import scipy\n",
        "import scipy.io as sio\n",
        "import torch.utils.data as data_utils\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import easydict\n",
        "\n",
        "\n",
        "###------------------------------------------------------\n",
        "torch.manual_seed(2019)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(2019)\n",
        "###------------------------------------------------------\n",
        "\n",
        "\n",
        "# D = 10;      D_min = 4; \n",
        "# D_fc = 5;    D_fc_min = 1; \n",
        "# N_fc = 20;   N_fc_min = 1;              # number of neurons in each D_fc layers\n",
        "\n",
        "# f1 = 10; f2 = 10; f3 = 10; f4 = 10; f5 = 10; f6 = 10; f7 = 10; f8 = 10; f9 = 10; f10 = 10; \n",
        "# f11 = 10; f12 = 10; f13 = 10; f14 = 10; f15 = 10; f16 = 10; f17 = 10; f18 = 10; f19 = 10; f20 = 10; f21 = 2;\n",
        "\n",
        "# f1 = 20; f2 = 20; f3 = 20; f4 = 20; f5 = 20; f6 = 20; f7 = 20; f8 = 20; f9 = 20; f10 = 20; \n",
        "# f11 = 20; f12 = 20; f13 = 20; f14 = 20; f15 = 20; f16 = 20; f17 = 20; f18 = 20; f19 = 20; f20 = 20; f21 = 2;\n",
        "\n",
        "# f1 = 30; f2 = 30; f3 = 30; f4 = 30; f5 = 30; f6 = 30; f7 = 30; f8 = 30; f9 = 30; f10 = 30; \n",
        "# f11 = 30; f12 = 30; f13 = 30; f14 = 30; f15 = 30; f16 = 30; f17 = 30; f18 = 30; f19 = 30; f20 = 30; f21 = 2;\n",
        "\n",
        "# f1 = 50; f2 = 50; f3 = 50; f4 = 50; f5 = 50; f6 = 50; f7 = 50; f8 = 50; f9 = 50; f10 = 50; \n",
        "# f11 = 50; f12 = 50; f13 = 50; f14 = 50; f15 = 50; f16 = 30; f17 = 30; f18 = 30; f19 = 30; f20 = 30; f21 = 2;\n",
        "\n",
        "f1 = 200; f2 = 200; f3 = 200; f4 = 200; f5 = 200; f6 = 200; f7 = 200; f8 = 200; f9 = 200; f10 = 200; \n",
        "f11 = 200; f12 = 200; f13 = 200; f14 = 200; f15 = 200; f16 = 200; f17 = 30; f18 = 30; f19 = 30; f20 = 30; f21 = 2;\n",
        "\n",
        "# f1 = 50\n",
        "\n",
        "# C_fmin = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]; \n",
        "# C_fmax = [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15];#,f16,f17,f18,f19,f20]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs_LAjnCsewY"
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "    \"alpha\": 0.01,\n",
        "    \n",
        "    \"phi1\": 0.01,\n",
        "    \"phi2\": 0.01,\n",
        "    \"phi3\": 0.01,\n",
        "    \"phi4\": 0.01,\n",
        "    \n",
        "    \"D\": 15,\n",
        "    \"D_min\": 4,\n",
        "    \"D_fc\": 5,          # fc layers\n",
        "    \"D_fc_min\": 1,\n",
        "    \"N_fc\": 128,        # neurons in fc\n",
        "    \"N_fc_min\": 1,\n",
        "    \n",
        "    \"C_fmin\": [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "    \"C_fmax\": [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11,f12,f13,f14,f15],\n",
        "\n",
        "    \"num_classes\": 2,\n",
        "    \"pop_size\": 5,\n",
        "    \n",
        "    \"epochs\": 50, #,\n",
        "    \"batch_size\": 100,\n",
        "    \"pop_size\": 5,\n",
        "    \"start_epoch\":0,\n",
        "    \"lr\": 0.0001,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight-decay\": 1e-4,\n",
        "    \"print-freq\": 500,\n",
        "    \"droprate\":0.2,\n",
        "    \"reduce\":0.5,\n",
        "    \n",
        "    #\"resume\": '/content/drive/My Drive/Normal_Op_DNet/F1_T1/best_cGA_checkpoint.pth.tar2',\n",
        "    #\"cGA_resume\": True,\n",
        "    \"resume\": False,\n",
        "    \"cGA_resume\": False,\n",
        "    \"bottleneck\": True,\n",
        "    \"fixed_flag\": True,\n",
        "    \"name\": '/content/drive/My Drive/Normal_Op_DNet/min1/F5_T2/',\n",
        "\n",
        "})\n",
        "\n",
        "args1 = easydict.EasyDict({\n",
        "})\n",
        "\n",
        "\n",
        "args.total_layers = args.D\n",
        "args.total_filters = sum(args.C_fmax[0:args.D])\n",
        "\n",
        "# args.f_fc = [20, 20, 20, 20, 20]#, 2]               # maximum number of neurons in each fc layer\n",
        "# args.f_fc = [10, 10, 10, 10, 10]#, 2]\n",
        "args.f_fc = [128, 128, 128, 128, 128]#, 2]\n",
        "args.N_fc_min = [1, 1, 1, 1, 1]                      # minimum number of neurons in each fc layer\n",
        "args.total_neurons = sum(args.f_fc[0:args.D_fc])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlvas2U-sgc2"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,order,F):\n",
        "        super(Net, self).__init__()\n",
        "        num_conv = 0; num_pool = 0; j = 0#num_relu = 0; num_BN = 0;\n",
        "        self.CC1 = nn.Sequential()\n",
        "        for i in range(len(order)):\n",
        "            if i == 0:\n",
        "                self.CC1.add_module('conv'+str(num_conv), nn.Conv2d(3, F[j], kernel_size=3, stride=2, padding=2))\n",
        "                self.CC1.add_module('bn'+str(num_conv), nn.BatchNorm2d(F[j])) \n",
        "                self.CC1.add_module('relu'+str(num_conv), nn.ReLU(True))\n",
        "                num_conv = num_conv + 1\n",
        "                \n",
        "            else:\n",
        "                if order[i] == 1:\n",
        "                    self.CC1.add_module('conv'+str(num_conv), nn.Conv2d(F[j], F[j+1], kernel_size=3, stride=2, padding=2))\n",
        "                    self.CC1.add_module('bn'+str(num_conv), nn.BatchNorm2d(F[j+1])) \n",
        "                    self.CC1.add_module('relu'+str(num_conv), nn.ReLU(True))\n",
        "                    num_conv = num_conv + 1; j = j+1\n",
        "#             print(num_conv)\n",
        "\n",
        "                if order[i] == 0:\n",
        "                    self.CC1.add_module('pool'+str(num_pool), nn.MaxPool2d(kernel_size=2, stride=1))\n",
        "                    num_pool = num_pool + 1\n",
        "#             if order[i] == 2:\n",
        "#                 self.CC1.add_module('relu'+str(num_relu), nn.ReLU(True))\n",
        "#                 num_relu = num_relu + 1\n",
        "#             if order[i] == 3:\n",
        "#                 self.CC1.add_module('BatchNorm'+str(num_BN), nn.BatchNorm2d(F[i]))\n",
        "#                 num_BN = num_BN + 1\n",
        "\n",
        "    def forward(self, x1):\n",
        "        #         print(z[a1-1])\n",
        "        y11 = self.CC1(x1)\n",
        "#         print('raw_cnn_out',y11.size())\n",
        "        y21 = y11.view(y11.size(0),-1)\n",
        "#         print('y21 in raw_cnn',y21.size())\n",
        "#         y31 = self.fc(y21)\n",
        "        #         print(y2)\n",
        "        return y11 #, y2, y1\n",
        "\n",
        "# raw_cnn = Net(order,F)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkSjPW55siMA"
      },
      "source": [
        "class DefineNet(nn.Module):\n",
        "    def __init__(self,order,F,fc_size,neurons):\n",
        "        super(DefineNet, self).__init__()\n",
        "        num_conv = 0; num_pool = 0; j = 0; #num_relu = 0; num_BN = 0;\n",
        "        self.CC1 = nn.Sequential()\n",
        "        for i in range(len(order)):\n",
        "            if i == 0:\n",
        "                self.CC1.add_module('conv'+str(num_conv), nn.Conv2d(3, F[j], kernel_size=3, stride=2, padding=2))\n",
        "                self.CC1.add_module('bn'+str(num_conv), nn.BatchNorm2d(F[j])) \n",
        "                self.CC1.add_module('relu'+str(num_conv), nn.ReLU())\n",
        "                num_conv = num_conv + 1\n",
        "            else: \n",
        "                if order[i] == 1:\n",
        "                    self.CC1.add_module('conv'+str(num_conv), nn.Conv2d(F[j], F[j+1], kernel_size=3, stride=2, padding=2))\n",
        "                    self.CC1.add_module('bn'+str(num_conv), nn.BatchNorm2d(F[j+1])) \n",
        "                    self.CC1.add_module('relu'+str(num_conv), nn.ReLU())\n",
        "                    j = j + 1; num_conv = num_conv + 1\n",
        "\n",
        "                if order[i] == 0:\n",
        "                    self.CC1.add_module('pool'+str(num_pool), nn.MaxPool2d(kernel_size=2, stride=1))\n",
        "                    num_pool = num_pool + 1\n",
        "         \n",
        "        self.classifier = nn.Sequential()\n",
        "        for k in range(len(neurons)):\n",
        "                if k == 0:\n",
        "                    self.classifier.add_module('fc'+str(k), nn.Linear(fc_size*fc_size*F[j], neurons[k]))\n",
        "                    self.classifier.add_module('relu'+str(k), nn.ReLU())\n",
        "                    self.classifier.add_module('DR'+str(k), nn.Dropout(p=0.2,inplace=True))\n",
        "                else:          # last layer in classifier \n",
        "                    self.classifier.add_module('fc'+str(k), nn.Linear(neurons[k-1], neurons[k]))\n",
        "                    self.classifier.add_module('relu'+str(k), nn.ReLU())\n",
        "                    self.classifier.add_module('DR'+str(k), nn.Dropout(p=0.2,inplace=True))\n",
        "#                 else:\n",
        "#                     self.classifier.add_module('fc'+str(k), nn.Linear(neurons[k-1], neurons[k]))\n",
        "#                     self.classifier.add_module('relu'+str(k), nn.ReLU(True))\n",
        "\n",
        "        self.fc = nn.Linear(neurons[k],2)\n",
        "        self.fc1 = nn.ReLU()\n",
        "        self.fc2 = torch.nn.Softmax(dim=1)\n",
        "    \n",
        "    \n",
        "    def forward(self, x1):\n",
        "            y1 = self.CC1(x1)\n",
        "            # print('y1',y1.size())\n",
        "            y2 = y1.view(y1.size(0),-1)\n",
        "            # print('y2',y2.size())\n",
        "            out = self.classifier(y2)\n",
        "            # print('out1',out.size())\n",
        "            out = self.fc(out)\n",
        "            # print('out2', out.size())\n",
        "            return out #, y2, y1\n",
        "\n",
        "# raw_cnn = Net(order,F)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv98ep0usjkE"
      },
      "source": [
        "args.order = [1, 1, 0, 1, 0, 1, 0, 1, 0, 1] ; \n",
        "args.filters =  [101, 101, 90, 93, 93, 95]\n",
        "args.fc_num = 1 \n",
        "args.neurons = [55]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDuDVcOcslKz",
        "outputId": "8653a2dc-c4f4-4872-f485-6ccf2c502893"
      },
      "source": [
        "    raw_cnn = Net(args.order, args.filters)\n",
        "#   print('raw_cnn', raw_cnn)\n",
        "    xx = torch.rand(1, 3, 100, 100);   # 100x100 : size of cell image in the Dataset\n",
        "    xx  = Variable(xx)\n",
        "    out = raw_cnn(xx)\n",
        "    print('out',out.size())\n",
        "    fc_size = out.size(2)\n",
        "    print('fc_size', fc_size)\n",
        "    \n",
        "    ###-----------------------------------------------------------\n",
        "    ### Initialize network\n",
        "    model = DefineNet(args.order, args.filters, fc_size, args.neurons)\n",
        "    print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out torch.Size([1, 95, 3, 3])\n",
            "fc_size 3\n",
            "Number of model parameters: 457943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMwL9RCCsmmr"
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "     \"resume\": '/content/drive/My Drive/cloned-repo/Public/itr_cGA_checkpoint.pth.tar60'\n",
        "})"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfhgag8Bsp4Y"
      },
      "source": [
        "if args.resume:\n",
        "#         if os.path.isfile(args.resume):\n",
        "#             print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "#             torch.load with map_location=torch.device('cpu')\n",
        "            checkpoint = torch.load(args.resume, 'cpu')\n",
        "\n",
        "\n",
        "            # epoch = checkpoint['epoch']\n",
        "\n",
        "            tr_fit = checkpoint['CP_trfit']\n",
        "            val_fit = checkpoint['CP_valfit']\n",
        "            tr_losses = checkpoint['CP_trloss']\n",
        "            val_losses = checkpoint['CP_valloss']\n",
        "            # init_stride = checkpoint['CP_init_stride']\n",
        "            # CM = checkpoint['CP_CM']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnG0PyIssCW"
      },
      "source": [
        "#mat_contents =  sio.loadmat('/home/baadalvm/soniya/COIL100Data/C100Train_Data.mat')\n",
        "mat_contents =  sio.loadmat('/content/drive/My Drive/Malaria/PW_Fold3/fold3_tedata.mat')\n",
        "mat_data= mat_contents['data_te']\n",
        "pydata = mat_data.transpose(3,2,0,1)\n",
        "Test_Data = torch.FloatTensor(pydata)\n",
        "\n",
        "#mat_labels =  sio.loadmat('/home/baadalvm/soniya/COIL100Data/C100Train_labels.mat')\n",
        "mat_labels =   sio.loadmat('/content/drive/My Drive/Malaria/PW_Fold3/fold3_tedata.mat')\n",
        "labels= mat_labels['labels_te']\n",
        "pylabels = labels.transpose(1,0)\n",
        "c = pylabels.astype(int)\n",
        "py1 = torch.LongTensor(c)\n",
        "Test_labels = py1.view(py1.size(0))\n",
        "\n",
        "# train_dataset = torch.utils.data.TensorDataset(Train_Data, Train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(Test_Data, Test_labels)\n",
        "\n",
        "# --- load datasets\n",
        "# train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hj8CFhfTafa",
        "outputId": "91a80079-4dcf-4dde-a9cc-3f3a84664207"
      },
      "source": [
        "idx = 365, # 1101, 453, 878\n",
        "\n",
        "input_img = Test_Data[idx]\n",
        "# print('Test_labels', Test_labels[idx])\n",
        "# print(input_img.size())\n",
        "\n",
        "img = input_img.unsqueeze(0)\n",
        "# print(img.size())\n",
        "out_idx = model(img).argmax(dim=1)\n",
        "# out_idx = output.argmax(dim=1)\n",
        "# print('output', output)\n",
        "# print('out_idx', out_idx)\n",
        "\n",
        "\n",
        "if Test_labels[idx] == 0:\n",
        "  if out_idx == 0:\n",
        "    print('Correct Prediction ==> target class: parasite cell,  and predicted class: parasite cell')\n",
        "  else:\n",
        "    print('Incorrect Prediction ==> target class: parasite cell,  and predicted class: normal cell')\n",
        "else:\n",
        "  if out_idx == 0:\n",
        "    print('Incorrect Prediction ==> target class: normal cell,  and predicted class: parasite cell')\n",
        "  else:\n",
        "    print('Correct Prediction ==> target class: normal cell,  and predicted class: normal cell')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct Prediction ==> target class: parasite cell,  and predicted class: parasite cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2J3MROZTqxJ"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}